<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Leonardo Emili Sapienza University of Rome, Italy emili.1802989@studenti.uniroma1.it" />
  <title>Homework 2: Aspect-Based Sentiment Analysis</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Homework 2: Aspect-Based Sentiment Analysis</h1>
<p class="author">Leonardo Emili<br />
Sapienza University of Rome, Italy<br />
<code>emili.1802989@studenti.uniroma1.it</code></p>
</header>
<h1 id="introduction">Introduction</h1>
<p>Aspect-Based Sentiment Analysis (ABSA) is a classification task that aims at identifying the aspects of a given target entity as well as the sentiment expressed toward each aspect. Moreover, in ABSA, we classify a sentence into a set of pre-identified categories with their polarities. Hence, we frame its formulation as a multi-step problem with the following phases: aspect terms extraction (A), aspect polarities identification (B), categories extraction (C), and category polarities identification (D), where task A+B identifies aspect polarities from the set of aspects extracted at step A, and similarly for task C+D. The main contributions of our work can be summarized as follows:</p>
<ul>
<li><p>Propose a multi-task transformer-based architecture to jointly learn all the subtasks.</p></li>
<li><p>Draw a quantitative analysis of the results achieved by the experiments.</p></li>
<li><p>Describe how to improve the drawbacks of proposed approaches with future work.</p></li>
</ul>
<h1 id="related-work">Related work</h1>
<p>A large interest has been spent on ABSA in recent years, both from industry (e.g. opinion mining of consumer reviews) and academia <span class="citation" data-cites="wang2020relational challenge-ds-absa xue2018aspect"></span>. Neural networks, and more recently, transformer-based architectures, keep breaking state-of-the-art (SOTA) results in many Natural Language Processing (NLP) tasks. Along these lines, in <span class="citation" data-cites="tang2016effective"></span> the authors propose a Target-Dependent LSTM architecture to encode the relatedness of a target word with its context words to infer the sentiment polarity towards the target term. In <span class="citation" data-cites="attention-based-lstm"></span> the authors investigate the role played by attention in determining the part of a sentence relevant to a specific aspect term.</p>
<h1 id="dataset-description">Dataset description</h1>
<p>The dataset consists of English sentences with pre-identified entities that can be either laptops or restaurants. Each input instance is annotated with a collection of aspect terms of such entities and their polarities. It is worth noting that multi-word aspect terms should be treated as single aspect terms. Furthermore, only for the instances from the restaurant domain, we have a set of categories and their polarities.</p>
<h1 id="preprocessing">Preprocessing</h1>
<p>We extract lemmas and Part-Of-Speech (POS) tags using the NLTK library <span class="citation" data-cites="nltk"></span>, and pre-compute WordPiece masks to get word-level representations <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Additionally, we apply data augmentation such that input sentences are duplicated by a factor of <span class="math inline"><em>n</em></span>, being <span class="math inline"><em>n</em></span> the number of aspect terms in the sentence, each time masking-out the other <span class="math inline"><em>n</em> − 1</span> terms to avoid data inconsistencies. Similar reasoning holds for aspect category terms. After this step, the size of the training set increases by more than 160%.</p>
<h1 id="contextualized-word-embeddings">Contextualized Word Embeddings</h1>
<p>In the past years, static word embeddings <span class="citation" data-cites="mikolov2013efficient pennington2014glove"></span> well served in many NLP tasks even though they were not suited for polysemous words <span class="citation" data-cites="hue2016different"></span>. Thanks to the recent success of contextualized embeddings <span class="citation" data-cites="Peters:2018 devlin2019bert"></span>, we are able to get context-specific representations of words depending on their surrounding terms. In this context, we employ BERT that conveniently uses WordPiece segmentation to avoid Out-Of-Vocabulary words.</p>
<h1 id="conditional-random-field">Conditional Random Field</h1>
<p>Linear chain Conditional Random Fields (CRFs) <span class="citation" data-cites="lafferty2001crf"></span> have proven their effectiveness in several sequence tagging tasks <span class="citation" data-cites="huang2015bidirectional"></span>. As a structured learning model, the idea is to chain predictions <span class="math inline"><em>Y</em></span> such that the value of <span class="math inline"><em>Y</em><sub><em>i</em></sub></span> depends on <span class="math inline"><em>Y</em><sub><em>i</em> − 1</sub></span> and to condition them on a sequence of observations <span class="math inline"><em>X</em></span>.</p>
<h1 id="methodology">Methodology</h1>
<p>In this section, we formalize the tasks of aspect terms identification <a href="#section:task_ab" data-reference-type="ref" data-reference="section:task_ab">7.1</a> and category identification <a href="#section:task_cd" data-reference-type="ref" data-reference="section:task_cd">7.2</a>. Furthermore, we propose a unified approach <a href="#section:unified" data-reference-type="ref" data-reference="section:unified">7.3</a> that enables the model to learn the two tasks in parallel in a <em>multitask learning</em> <span class="citation" data-cites="Caruana96algorithmsand"></span> fashion.</p>
<h2 id="section:task_ab">Aspect terms identification</h2>
<p>Given an input sentence of tokens <span class="math inline"><em>x</em><sub>1</sub><em>x</em><sub>2</sub>⋯<em>x</em><sub><em>n</em></sub></span>, our objective goal is to determine the range of contiguous tokens <span class="math inline"><em>x</em><sub><em>i</em></sub>⋯<em>x</em><sub><em>i</em> + <em>k</em></sub></span> that belong to the same aspect term. For instance, in the sentence <em>The food is tasty and portion sizes are appropriate.</em> we recognize <em>food</em> and <em>portion sizes</em> as target aspect terms. We frame the problem as a Named Entity Recognition (NER) task, where aspect terms are annotated according to the Inside–outside–beginning (IOB/BIO) tagging scheme, and entity types (e.g. LOC, ORG) are dropped. Consequently, we model multi-word aspect terms using an initial <em>begin</em> symbol, followed by a collection of <em>inside</em> symbols. To extract aspect terms polarities, we can extend this reasoning and pair each symbol of the BIO tagging scheme to the desired polarity <span class="citation" data-cites="li2019exploiting"></span>. The <em>outside</em> tag does not change since it does not involve polarities. To extract the sentiment of a candidate aspect term, we apply an aggregation strategy over the predicted labels (e.g. first or most common polarity aspect-wise).</p>
<h2 id="section:task_cd">Category identification</h2>
<p>The naïve approach is to infer the set of categories of a sentence by looking at the probabilities of each of them given the input sentence. The intuition is that if the word <em>food</em> occurs in a sentence, there will be a good chance of observing the homonymous class for that sentence. More generally, we expect a high probability for class <span class="math inline"><em>x</em></span> if the input tokens are related to the domain of <span class="math inline"><em>x</em></span>, and a low probability for class <span class="math inline"><em>y</em></span> if none of the input tokens are related to <span class="math inline"><em>y</em></span>. To identify polarities we apply the same reasoning as in <a href="#section:task_ab" data-reference-type="ref" data-reference="section:task_ab">7.1</a>, considering as target vocabulary the Cartesian product of the category class and the polarity class.</p>
<h2 id="section:unified">Unified approach</h2>
<p>Thanks to the big success of multitask learning approaches <span class="citation" data-cites="conia-etal-2021-unify-srl raganato2017neural collobert2008unified"></span>, we propose a unified model that tries to solve both tasks in parallel. According to the hypothesis for which aspect terms can be informative for predicting aspect categories <span class="citation" data-cites="xue2017mtna"></span>, we leverage both the input sentence and the recognized aspect terms for the extraction. We define a loss function for each subtask and optimize for them <em>jointly</em> to improve subtasks A+B and C+D.</p>
<h1 id="model-architecture">Model architecture</h1>
<p>In this section, we describe the architecture for the multitask approach. Solving only for task B, or D, can be achieved as a simplification of this model, where pre-identified aspect terms, or aspect categories, are fed as input, and we analyze their relatedness with respect to the input sentence.</p>
<h2 id="input-representation">Input representation</h2>
<p>As the core representation of the input sequences, we stack the last four layers of BERT embeddings to have a context-aware representation of the tokens. Following <span class="citation" data-cites="alghanmi2020combining"></span>, we apply an average pooling layer and concatenate the resulting word-level BERT embeddings with static word embeddings (i.e. Word2Vec).</p>
<h2 id="pos-embeddings">POS embeddings</h2>
<p>To further enhance the quality of our input embeddings, we append a learnable <span class="math inline"><em>k</em></span>-dimensional POS embedding. We expect it to boost the performance since some parts of speech are less observed when annotating words as aspect terms <a href="#fig:pos_tag_distribution" data-reference-type="ref" data-reference="fig:pos_tag_distribution">[fig:pos_tag_distribution]</a>. The value of <span class="math inline"><em>k</em></span> is experimentally found through hyperparameter tuning.</p>
<h2 id="sentence-encoder">Sentence encoder</h2>
<p>Leveraging the sequential nature of the input sentences, we employ a Bidirectional Long Short-Term Memory (BiLSTM) to extract latent representations of the input words. Their gated architecture enables to capture short-term dependencies while also retraining part of long-term dependencies. However, since hidden state <span class="math inline"><em>h</em><sub><em>i</em></sub></span> depends on the computation of <span class="math inline"><em>h</em><sub><em>i</em> − 1</sub></span> for both directions, it heavily affects parallelism. To overcome this issue, we experiment with self-attention layers <span class="citation" data-cites="vaswani2017attention"></span> and transformer encoders. Differently from Recurrent Neural Networks (RNNs), they attend to information from the whole input sequence rather than compressing it into single hidden vector states, with corresponding information loss <span class="citation" data-cites="bahdanau2016neural"></span>.</p>
<h2 id="task-specific-decoders">Task-specific decoders</h2>
<p>At the end of the encoding pipeline, we train two linear decoders to map predictions to the corresponding output space. Their linear nature confirms the intuition that the subtasks should be informative to each other. The multitask model should benefit from it, learning a shared hidden representation.</p>
<h1 id="experimental-setup">Experimental setup</h1>
<p>In this section, we define the settings and the tools <span class="citation" data-cites="wandb"></span> used to evaluate the experiments.</p>
<h2 id="datasets">Datasets</h2>
<p>For the purpose of this project, we do not use any external training corpus. However, for some experiments, we find it beneficial to train our model on a subset of the available data. Experiments that show this behavior are reported with <span class="math inline"><em>Φ</em><sub><em>d</em></sub></span>, with <span class="math inline"><em>d</em> ∈ {<em>l</em><em>a</em><em>p</em><em>t</em><em>o</em><em>p</em>, <em>r</em><em>e</em><em>s</em><em>t</em><em>a</em><em>u</em><em>r</em><em>a</em><em>n</em><em>t</em>}</span>, referring to models trained only on that subset of data.</p>
<h2 id="evaluation-metrics">Evaluation metrics</h2>
<p>As an evaluation framework, we consider multiple metrics in order to assess the quality of a particular model. Namely, in Table <a href="#tab:model_comparison" data-reference-type="ref" data-reference="tab:model_comparison">[tab:model_comparison]</a> we depict the highest F1-macro and F1-micro scores achieved by each architecture. However, for the testing phase, we pick the model with the highest F1-macro score.</p>
<h2 id="hyperparameters">Hyperparameters</h2>
<p>In Table <a href="#tab:hparms" data-reference-type="ref" data-reference="tab:hparms">1</a>, we present a subset of the hyperparameters used in our models. However, we do not intend it to be an exhaustive list of all the hyperparameters and configurations used. They can be reached <a href="https://wandb.ai/leonardoemili/nlp_hw2?workspace=user-leonardoemili">here</a>.</p>
<h2 id="training-details">Training details</h2>
<p>In order to alleviate the memory requirements of the transformer-based experiments and speed up training, we use axial positional encodings <span class="citation" data-cites="kitaev2020reformer ho2019axial"></span> to reduce the number of parameters of the network, as well as APEX mixed-precision training and frozen word embeddings. We include weighted loss functions according to the distribution of polarity labels in the training set.</p>
<h1 id="experimental-results">Experimental results</h1>
<p>Table <a href="#tab:model_comparison" data-reference-type="ref" data-reference="tab:model_comparison">[tab:model_comparison]</a> depicts the ablation study derived from different experiments of the multitask learner. It is worth observing how the bidirectional LSTM model achieves the best performance when exploiting all the core features. In Figures <a href="#fig:ner_cf" data-reference-type="ref" data-reference="fig:ner_cf">2</a> and <a href="#fig:category_cf" data-reference-type="ref" data-reference="fig:category_cf">[fig:category_cf]</a>, we can observe the relative confusion matrices. It confirms our intuition that recurrent neural models overcome the difficulties faced by simpler multi-layer perceptron architectures. Moreover, we can notice a general performance degradation when adding a self-attention layer on top of the recurrent layer. The CRF-BiLSTM model achieves similar results without significant performance gain. Please refer to Figure <a href="#fig:multistep" data-reference-type="ref" data-reference="fig:multistep">3</a> for the complete architecture. Furthermore, training on a subset of the available data has proven beneficial only in the category identification task, with improvements up to 3%. Additionally, word-level tokens have proven useful, and removing them lead the scores down to 48.56% on task A+B and 52.92% on task C+D.</p>
<h2 id="cross-domain-evaluation">Cross-domain evaluation</h2>
<p>We additionally try the following experiment masking out labels for aspect categories: first train model <span class="math inline"><em>Φ</em><sub><em>r</em><em>e</em><em>s</em><em>t</em><em>a</em><em>u</em><em>r</em><em>a</em><em>n</em><em>t</em></sub></span> on restaurant data and evaluate on laptop data, and vice versa for <span class="math inline"><em>Φ</em><sub><em>l</em><em>a</em><em>p</em><em>t</em><em>o</em><em>p</em></sub></span>. The resulting macro F1 scores on task A+B are respectively 19.76% and 16.68%. We observe that both the models overfit the training data and lack generalization capabilities. It is worth noting how, without masking, the former improves up to 21.76%. It gives us a reason to believe that multitask learning is a good choice even in such transfer learning settings.</p>
<h1 id="conclusion-and-future-work">Conclusion and future work</h1>
<p>We developed different strategies to tackle the ABSA pipeline and eventually discovered the validity of the multitask learning approach against individual learners. We observed through extensive experimentation that recurrent neural models paired with contextual embeddings lead to good performance. As a crucial drawback of the system, we believe that frozen word embeddings heavily limit the performance. Future work would include external training corpora, train with learnable word embeddings, and apply more sophisticated data augmentation techniques <span class="citation" data-cites="liesting2021augmentation"></span>.</p>
<div class="figure*">
<p><img src="images/pos_tags_distribution.png" style="width:110.0%" alt="image" /></p>
</div>
<figure>
<img src="images/f1_plot.png" id="fig:f1_plot" style="width:56.0%" alt="Diagram showing the macro F1 score over the epochs. Dashed lines denote the highest values for the category terms identification task and the aspect terms identification task, respectively yellow and green line." /><figcaption aria-hidden="true">Diagram showing the macro F1 score over the epochs. Dashed lines denote the highest values for the category terms identification task and the aspect terms identification task, respectively yellow and green line.</figcaption>
</figure>
<figure>
<img src="images/ner_cf.png" id="fig:ner_cf" style="width:56.0%" alt="Normalized confusion matrix for the aspects identification task. It is worth observing that the model performs much better on positive aspect terms since the dataset is highly unbalanced towards the majority class [fig:pos_tag_distribution]." /><figcaption aria-hidden="true">Normalized confusion matrix for the aspects identification task. It is worth observing that the model performs much better on positive aspect terms since the dataset is highly unbalanced towards the majority class <a href="#fig:pos_tag_distribution" data-reference-type="ref" data-reference="fig:pos_tag_distribution">[fig:pos_tag_distribution]</a>.</figcaption>
</figure>
<figure>
<img src="images/model_diagram.png" id="fig:multistep" style="width:50.0%" alt="Diagram showing the architecture of the multistep model for multitask learning. Differences from the base Bi-LSTM architecture are highlighted in red: (1) refers to the BiLSTM (attention) architecture with positional embeddings, (2) highlights the CRF layer used to decode emission scores using the Viterbi algorithm." /><figcaption aria-hidden="true">Diagram showing the architecture of the multistep model for multitask learning. Differences from the base Bi-LSTM architecture are highlighted in red: <em>(1)</em> refers to the BiLSTM (attention) architecture with positional embeddings, <em>(2)</em> highlights the CRF layer used to decode emission scores using the Viterbi algorithm.</figcaption>
</figure>
<div class="table*">
<div class="tabular">
<p><span>llccccc</span> &amp; &amp; &amp; &amp;<br />
&amp; &amp; <span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>a</em><em>c</em><em>r</em><em>o</em></sup></span> &amp; <span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>i</em><em>c</em><em>r</em><em>o</em></sup></span> &amp; &amp; <span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>a</em><em>c</em><em>r</em><em>o</em></sup></span> &amp; <span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>i</em><em>c</em><em>r</em><em>o</em></sup></span><br />
</p>
<p>&amp; BERT &amp; 35.82 &amp; 47.73 &amp; &amp; 34.59 &amp; 41.97<br />
&amp; + Word2Vec &amp; 36.95 &amp; 50.09 &amp; &amp; 33.76 &amp; 42.51<br />
&amp; + POS &amp; 38.10 &amp; 48.58 &amp; &amp; 36.42 &amp; 42.86<br />
</p>
<p>&amp; BERT &amp; 49.54 &amp; 59.91 &amp; &amp; 50.69 &amp; 62.34<br />
&amp; + Word2Vec &amp; 49.20 &amp; 61.50 &amp; &amp; 51.63 &amp; 64.50<br />
&amp; + POS &amp; <strong>50.04</strong> &amp; <strong>65.02</strong> &amp; &amp; <strong>55.00</strong> &amp; <strong>66.47</strong><br />
</p>
<p>&amp; BERT &amp; 47.79 &amp; 58.47 &amp; &amp; 49.05 &amp; 60.18<br />
&amp; + Word2Vec &amp; 47.98 &amp; 59.22 &amp; &amp; 49.34 &amp; 60.79<br />
&amp; + POS &amp; 49.46 &amp; 60.18 &amp; &amp; 53.88 &amp; 64.05<br />
</p>
<p>&amp; BERT &amp; 47.57 &amp; 57.17 &amp; &amp; 48.95 &amp; 59.48<br />
&amp; + Word2Vec &amp; 48.11 &amp; 60.10 &amp; &amp; 48.03 &amp; 59.22<br />
&amp; + POS &amp; 49.85 &amp; 62.93 &amp; &amp; 51.13 &amp; 62.88<br />
</p>
<p>&amp; BERT &amp; 35.92 &amp; 48.19 &amp; &amp; 49.44 &amp; 61.07<br />
&amp; + Word2Vec &amp; 36.79 &amp; 50.10 &amp; &amp; 49.93 &amp; 61.86<br />
&amp; + POS &amp; 37.33 &amp; 50.53 &amp; &amp; 51.09 &amp; 63.01<br />
</p>
</div>
</div>
<div class="table*">
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;" rowspan="2">Model</td>
<td style="text-align: center;" colspan="2">Aspects</td>
<td style="text-align: center;"></td>
<td style="text-align: center;" colspan="2">Categories <span class="math inline"><sup>(<em>Φ</em><sub><em>r</em><em>e</em><em>s</em><em>t</em><em>a</em><em>u</em><em>r</em><em>a</em><em>n</em><em>t</em></sub>)</sup></span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>a</em><em>c</em><em>r</em><em>o</em></sup></span></td>
<td style="text-align: center;"><span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>i</em><em>c</em><em>r</em><em>o</em></sup></span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>a</em><em>c</em><em>r</em><em>o</em></sup></span></td>
<td style="text-align: center;"><span class="math inline"><em>F</em><sub>1</sub><sup><em>m</em><em>i</em><em>c</em><em>r</em><em>o</em></sup></span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Aspect classifier</td>
<td style="text-align: center;">41.25</td>
<td style="text-align: center;">60.16</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">Category classifier</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">38.23</td>
<td style="text-align: center;">49.12</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Multistep classifier</td>
<td style="text-align: center;"><strong>50.04</strong></td>
<td style="text-align: center;"><strong>65.02</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>55.00</strong></td>
<td style="text-align: center;"><strong>66.47</strong></td>
</tr>
</tbody>
</table>
</div>
<div id="tab:hparms">
<table>
<caption>List of hyperparameters.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Hyperparameter</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Learning rate</td>
<td style="text-align: center;">0.05</td>
</tr>
<tr class="even">
<td style="text-align: left;">Optimizer</td>
<td style="text-align: center;">Adam</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Loss function</td>
<td style="text-align: center;">Cross entropy</td>
</tr>
<tr class="even">
<td style="text-align: left;">POS embedding size</td>
<td style="text-align: center;">30</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Hidden size</td>
<td style="text-align: center;">512</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dropout</td>
<td style="text-align: center;">0.65</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Epochs</td>
<td style="text-align: center;">50</td>
</tr>
<tr class="even">
<td style="text-align: left;">Word encoder</td>
<td style="text-align: center;">bert-base-uncased</td>
</tr>
</tbody>
</table>
</div>
<div class="figure*">
<p><img src="images/categories_cf.png" style="width:110.0%" alt="image" /></p>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>We define our pooling strategy, similar to AllenNLP’s <a href="https://docs.allennlp.org/main/api/modules/token_embedders/pretrained_transformer_mismatched_embedder/">implementation</a> <span class="citation" data-cites="gardner2018allennlp"></span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
